# پیکربندی و استفاده از LLM

### 1. چگونه به OpenAI از طریق یک سرور پروکسی در چین دسترسی پیدا کنیم؟

Dify از نام دامنه‌های API سفارشی برای OpenAI و هر سرور API مدل بزرگ سازگار با OpenAI پشتیبانی می‌کند. در نسخه جامعه، می‌توانید آدرس سرور هدف را از طریق **تنظیمات --> ارائه دهندگان مدل --> OpenAI --> ویرایش API** وارد کنید.

### 2. چگونه یک مدل پایه را انتخاب کنیم؟

* **gpt-3.5-turbo**: gpt-3.5-turbo نسخه ارتقا یافته‌ای از سری مدل gpt-3 است. این مدل قوی‌تر از gpt-3 است و می‌تواند وظایف پیچیده‌تری را انجام دهد. این مدل پیشرفت‌های قابل توجهی در درک متون طولانی و استدلال متقابل سند دارد. gpt-3.5-turbo می‌تواند متن‌های منسجم‌تر و متقاعدکننده‌تری تولید کند. همچنین این مدل در خلاصه‌سازی، ترجمه و نوشتن خلاقانه به طور قابل توجهی بهبود یافته است. تخصص در: **درک متن طولانی، استدلال متقابل سند، خلاصه‌سازی، ترجمه، نوشتن خلاقانه.**
* **gpt-4**: gpt-4 جدیدترین و قدرتمندترین مدل زبان ترانسفورمری است. این مدل تقریباً 20 میلیارد پارامتر آموزش داده شده دارد که آن را در تمام وظایف زبانی، به ویژه آنهایی که به درک عمیق و تولید پاسخ‌های طولانی و پیچیده نیاز دارند، در سطح بالاتری قرار می‌دهد. gpt-4 می‌تواند همه جنبه‌های زبان انسانی، از جمله درک مفاهیم انتزاعی و استدلال متقابل صفحه را انجام دهد. gpt-4 اولین سیستم درک زبان جهانی است که می‌تواند هر وظیفه پردازش زبان طبیعی را در حوزه هوش مصنوعی انجام دهد. تخصص در: **تمام وظایف NLP، درک زبان، تولید متن طولانی، استدلال متقابل سند، درک مفاهیم انتزاعی.** برای جزئیات بیشتر، به [مستندات](https://platform.openai.com/docs/models/overview) مراجعه کنید.

### 3. چرا توصیه می‌شود که max_tokens را کوچکتر تنظیم کنیم؟

در پردازش زبان طبیعی، خروجی‌های متنی طولانی‌تر معمولاً به زمان محاسبه و منابع بیشتری نیاز دارند. بنابراین، محدود کردن طول متن خروجی می‌تواند تا حدودی هزینه محاسباتی و زمان را کاهش دهد. به عنوان مثال، تنظیم max_tokens=500 به معنی فقط در نظر گرفتن 500 توکن اول از متن خروجی است و هر قسمتی فراتر از این طول دور انداخته خواهد شد. این امر تضمین می‌کند که طول متن خروجی از محدوده قابل قبول LLM تجاوز نمی‌کند و منابع محاسباتی را بهینه می‌کند و راندمان مدل را بهبود می‌بخشد. علاوه بر این، تنظیم max_tokens کوچکتر به شما امکان می‌دهد تا یک prompt طولانی‌تر داشته باشید. به عنوان مثال، gpt-3.5-turbo محدودیت 4097 توکن دارد. اگر max_tokens=4000 باشد، فقط 97 توکن برای prompt باقی می‌ماند و تجاوز به این محدودیت باعث خطا می‌شود.

### 4. چگونه می‌توانیم متون طولانی در مجموعه داده‌ها را به طور معقولی تقسیم کنیم؟

در برخی از کاربردهای پردازش زبان طبیعی، متون معمولاً به صورت پاراگراف یا جمله تقسیم می‌شوند تا اطلاعات معنایی و ساختاری موجود در متن را بهتر مدیریت و درک کنند. کوچکترین واحد تقسیم بندی به وظیفه خاص و پیاده‌سازی فنی بستگی دارد. به عنوان مثال:

* برای وظایف طبقه‌بندی متن، متون معمولاً به صورت جمله یا پاراگراف تقسیم می‌شوند.
* برای وظایف ترجمه ماشین، کل جملات یا پاراگراف‌ها به عنوان واحدهای تقسیم بندی استفاده می‌شوند.

در نهایت، آزمایشات و ارزیابی‌ها برای تعیین مناسب‌ترین تکنیک جاسازی و واحد تقسیم بندی مورد نیاز است. می‌توانید عملکرد تکنیک‌ها و واحدهای تقسیم بندی مختلف را در مجموعه داده آزمایشی مقایسه کنید و بهترین راه‌حل را انتخاب کنید.

### 5. از چه تابع فاصله‌ای برای بخش‌بندی مجموعه داده استفاده می‌کنیم؟

ما از [شباهت کسینوسی](https://en.wikipedia.org/wiki/Cosine_similarity) استفاده می‌کنیم. انتخاب تابع فاصله معمولاً بحرانی نیست. جاسازی‌های OpenAI به طول 1 نرمال می‌شوند، به این معنی که:

استفاده از ضرب نقطه‌ای می‌تواند سرعت محاسبه شباهت کسینوسی را تا حدودی افزایش دهد.

شباهت کسینوسی و فاصله اقلیدسی به رتبه‌بندی یکسانی منجر می‌شود.

* اگر بردارهای جاسازی نرمال شده برای محاسبه شباهت کسینوسی یا فاصله اقلیدسی استفاده شوند و بردارها بر اساس این معیارهای شباهت رتبه‌بندی شوند، نتایج رتبه‌بندی یکسان خواهد بود. این به این دلیل است که پس از نرمال شدن، طول بردارها دیگر بر روابط نسبی آن‌ها تأثیر نمی‌گذارد. فقط اطلاعات جهت‌گیری حفظ می‌شود. بنابراین، هنگام استفاده از بردارهای نرمال شده برای اندازه‌گیری شباهت، روش‌های اندازه‌گیری مختلف نتایج رتبه‌بندی یکسانی را به همراه خواهند داشت. پس از نرمال شدن، تمام بردارها به طول 1 مقیاس می‌شوند، به این معنی که همه آن‌ها بر روی طول واحد قرار دارند. بردارهای واحد فقط جهت را بدون اندازه توصیف می‌کنند، زیرا طول آن‌ها همیشه 1 است. _برای اصول خاص، می‌توانید از ChatGPT سوال کنید._

هنگامی که بردارهای جاسازی به طول 1 نرمال می‌شوند، محاسبه شباهت کسینوسی بین دو بردار می‌تواند به ضرب نقطه‌ای آن‌ها ساده شود. از آنجا که طول بردارهای نرمال شده همه 1 هستند، نتیجه ضرب نقطه‌ای معادل نتیجه شباهت کسینوسی است. با توجه به اینکه عملیات ضرب نقطه‌ای از سایر معیارهای شباهت (مانند فاصله اقلیدسی) سریع‌تر است، استفاده از بردارهای نرمال شده برای محاسبات ضرب نقطه‌ای می‌تواند تا حدودی راندمان محاسباتی را بهبود بخشد.

### 6. چگونه می‌توانیم سهمیه‌های آزمایشی رایگان برای مدل‌های Zhipu·AI، iFlytek Spark و MiniMax دریافت کنیم؟

ما با ارائه دهندگان مدل اصلی همکاری می‌کنیم تا سهمیه‌های آزمایشی توکن رایگان مشخصی را برای کاربران چینی ارائه دهیم. از طریق Dify **تنظیمات --> ارائه دهندگان مدل --> نمایش بیشتر ارائه دهندگان مدل**، روی "دریافت رایگان" در آیکون‌های Zhipu·AI، iFlytek Spark یا MiniMax کلیک کنید. اگر ورودی را در رابط انگلیسی نمی‌بینید، زبان محصول را به چینی تغییر دهید:

* **Zhipu·AI: 10 میلیون توکن رایگان دریافت کنید.** روی "دریافت رایگان" کلیک کنید، شماره تلفن و کد تأیید خود را وارد کنید تا سهمیه را دریافت کنید، صرف نظر از اینکه قبلاً در Zhipu·AI ثبت نام کرده‌اید یا خیر.
* **iFlytek Spark (مدل V1.5، مدل V2.0): 6 میلیون توکن رایگان دریافت کنید، 3 میلیون توکن برای هر مدل، سهمیه‌ها قابل تعویض نیستند.** از طریق Dify وارد شوید، ثبت نام را در پلتفرم باز iFlytek Spark تکمیل کنید (فقط برای شماره تلفن‌هایی که قبلاً در iFlytek Spark ثبت نام نکرده‌اند)، به Dify برگردید، 5 دقیقه صبر کنید و صفحه را تازه کنید تا سهمیه موجود را مشاهده کنید.
* **MiniMax: 1 میلیون توکن رایگان دریافت کنید.** روی "دریافت رایگان" کلیک کنید تا سهمیه را بدون ثبت نام دستی دریافت کنید، صرف نظر از اینکه قبلاً در MiniMax ثبت نام کرده‌اید یا خیر.

پس از اعتبار سهمیه آزمایشی، مدل مورد نیاز خود را در **ترتیب prompt --> مدل و پارامترها --> مدل زبان** انتخاب کنید.

### 7. هنگام وارد کردن کلید OpenAI، اعتبارسنجی با خطای " اعتبارسنجی ناموفق: شما از سهمیه فعلی خود فراتر رفتید، لطفاً طرح و جزئیات صورت‌حساب خود را بررسی کنید." چه دلیلی دارد؟

این نشان می‌دهد که حساب کلید OpenAI شما از اعتبار خالی شده است. لطفاً به OpenAI مراجعه کنید تا شارژ کنید.

### 8. هنگام استفاده از کلید OpenAI برای مکالمه در برنامه، با خطاهای زیر مواجه شدم. چه دلیلی دارد؟

خطای اول:

```JSON
سرور با خطای داخلی مواجه شد و نتوانست درخواست شما را کامل کند. یا سرور بیش از حد بارگذاری شده است یا خطایی در برنامه وجود دارد
```

خطای دوم:

```JSON
حداکثر نرخ برای default-gpt-3.5-turbo در سازمان org-wDrZCxxxxxxxxxissoZb در درخواست‌های در دقیقه فراتر رفت. حد: 3 / دقیقه. لطفاً بعد از 20 ثانیه دوباره تلاش کنید. اگر همچنان با مشکل مواجه شدید، از طریق مرکز راهنما در help.openai.com با ما تماس بگیرید. لطفاً برای افزایش محدودیت نرخ، روش پرداخت را به حساب خود اضافه کنید. برای اضافه کردن روش پرداخت به https://platform.openai.com/account/billing مراجعه کنید.
```

لطفاً بررسی کنید که آیا به حداکثر نرخ تماس API رسمی رسیده‌اید یا خیر. برای جزئیات بیشتر به [مستندات رسمی OpenAI](https://platform.openai.com/docs/guides/rate-limits) مراجعه کنید.

### 9. پس از استقرار خودکار توسط کاربر، Zhichat در دسترس نیست و خطا به شرح زیر است: "آرگومان درخواست نامعتبر ارائه شده است: functions." چگونه می‌توان این مشکل را حل کرد؟

اول، بررسی کنید که آیا نسخه‌های سمت جلو و سمت عقب جدیدترین و سازگار هستند یا خیر. دوم، این خطا ممکن است به این دلیل رخ دهد که شما از یک کلید Azure OpenAI استفاده می‌کنید اما مدل را با موفقیت مستقر نکرده‌اید. بررسی کنید که آیا مدل در Azure OpenAI شما مستقر شده است یا خیر. نسخه مدل gpt-3.5-turbo باید 0613 یا بالاتر باشد (از آنجا که نسخه‌های قبل از 0613 از قابلیت تماس تابعی که توسط Zhichat استفاده می‌شود پشتیبانی نمی‌کنند، و این امر آن را غیرقابل استفاده می‌کند).

### 10. هنگام تنظیم کلید OpenAI، خطای زیر نمایش داده می‌شود. چه دلیلی دارد؟

```JSON
خطا در ارتباط با OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): حداکثر تلاش مجدد فراتر رفت با url: /v1/chat/completions (Caused by NewConnectionError(<urllib3.connection.HTTPSConnection object at 0x7f0462ed7af0>; نتوانست یک اتصال جدید ایجاد کند: [Errno -3] خطای موقت در حل نام'))
```

معمولاً این به دلیل تنظیم پروکسی در محیط شما است. لطفاً بررسی کنید که آیا پروکسی تنظیم شده است یا خیر.

### 11. هنگام تعویض مدل‌ها در برنامه، با خطای زیر مواجه شدم. چگونه می‌توان این مشکل را حل کرد؟

```JSON
Anthropic: کد خطا: 400 - 'error': 'type': "خطای درخواست نامعتبر، 'message': 'temperature: range: -1 or 0..1)
```

هر مدل دارای مقادیر پارامتر متفاوتی است. مقادیر پارامتر را با توجه به محدوده مدل فعلی تنظیم کنید.

### 12. با خطای زیر مواجه شدم. چگونه می‌توان این مشکل را حل کرد؟

```JSON
پرس و جو یا prompt پیشوند خیلی طولانی است، می‌توانید prompt پیشوند را کاهش دهید، یا max token را کاهش دهید، یا به یک LLM با محدودیت توکن بزرگتر سوئیچ کنید
```

در تنظیمات پارامترها در صفحه تنظیمات، مقدار "max token" را کاهش دهید.

### 13. مدل پیش‌فرض در Dify چیست و آیا می‌توان از مدل‌های منبع باز استفاده کرد؟

مدل پیش‌فرض را می‌توان در **تنظیمات - ارائه دهندگان مدل** پیکربندی کرد. در حال حاضر، از مدل‌های تولید متن از ارائه دهندگان مانند OpenAI / Azure OpenAI / Anthropic پشتیبانی می‌کند و همچنین از ادغام مدل‌های منبع باز میزبانی شده در Hugging Face / Replicate / xinference پشتیبانی می‌کند.

### 14. در نسخه جامعه، چرا **حالت بخش‌بندی Q&A** مجموعه داده به طور مداوم "در صف انتظار" نمایش داده می‌شود؟

بررسی کنید که آیا کلید API مدل جاسازی که در حال استفاده از آن هستید به حداکثر نرخ رسیده‌ است یا خیر.

### 15. هنگامی که کاربران در حین استفاده از برنامه با خطای "توکن نامعتبر" مواجه می‌شوند، چگونه می‌توان این مشکل را حل کرد؟

اگر با خطای "توکن نامعتبر" مواجه شدید، راه‌حل‌های زیر را امتحان کنید:

* حافظه پنهان مرورگر را پاک کنید (کوکی‌ها، ذخیره‌سازی جلسه و ذخیره‌سازی محلی). اگر از یک برنامه تلفن همراه استفاده می‌کنید، حافظه پنهان برنامه مربوطه را پاک کنید و دوباره به آن دسترسی پیدا کنید.
* یک URL برنامه جدید ایجاد کنید و دوباره URL را وارد کنید.

### 16. محدودیت‌های اندازه برای آپلود اسناد مجموعه داده چیست؟

در حال حاضر، حداکثر اندازه برای آپلود یک سند واحد 15MB است، با محدودیت کل سند 100. اگر نیاز به تنظیم این محدودیت‌ها برای نسخه مستقر شده در محلی دارید، به [مستندات](https://docs.dify.ai/v/zh-hans/getting-started/faq/install-faq#11.-ben-di-bu-shu-ban-ru-he-jie-jue-shu-ju-ji-wen-dang-shang-chuan-de-da-xiao-xian-zhi-he-shu-liang) مراجعه کنید.

### 17. چرا انتخاب مدل Claude هنوز سهمیه OpenAI را مصرف می‌کند؟

از آنجا که Claude از مدل جاسازی پشتیبانی نمی‌کند، فرآیند جاسازی و سایر تولید مکالمه به طور پیش‌فرض از کلید OpenAI استفاده می‌کنند، بنابراین سهمیه OpenAI را مصرف می‌کنند. همچنین می‌توانید مدل‌های استنباط پیش‌فرض و مدل‌های جاسازی دیگر را در **تنظیمات - ارائه دهندگان مدل** تنظیم کنید.

### 18. چگونه می‌توانم استفاده از داده‌های متنی بیشتر را به جای توانایی‌های تولید مدل خودم کنترل کنم؟

استفاده از مجموعه داده به شرح مجموعه داده بستگی دارد. شرح مجموعه داده را تا حد امکان واضح و شفاف کنید. برای تکنیک‌های خاص نوشتن، به [این مستندات](https://docs.dify.ai/v/zh-hans/advanced/datasets) مراجعه کنید.

### 19. هنگام آپلود اسناد مجموعه داده در اکسل، چگونه می‌توانیم آن‌ها را بهتر بخش‌بندی کنیم؟

عنوان را در ردیف اول تنظیم کنید و محتوا را در هر ردیف بعدی بدون تنظیمات عنوان اضافی یا قالب‌های جدول پیچیده نمایش دهید.

به عنوان مثال، در جدول زیر، فقط عنوان ردیف دوم را حفظ کنید. ردیف اول (جدول 1) یک عنوان اضافی است و باید حذف شود.

### 20. چرا حتی با خرید ChatGPT Plus، نمی‌توانم از GPT-4 در Dify استفاده کنم؟

API مدل GPT-4 OpenAI و ChatGPT Plus دو محصول جداگانه با هزینه‌های جداگانه هستند. API مدل دارای قیمت‌گذاری جداگانه‌ای است. به [مستندات قیمت‌گذاری OpenAI](https://openai.com/pricing) مراجعه کنید. برای درخواست دسترسی پرداخت شده، ابتدا باید یک کارت را به آن متصل کنید. اتصال کارت دسترسی به GPT-3.5 را می‌دهد اما دسترسی به GPT-4 را نمی‌دهد. دسترسی به GPT-4 به صورتحساب پرداخت شده نیاز دارد. برای جزئیات بیشتر به [مستندات رسمی OpenAI](https://platform.openai.com/account/billing/overview) مراجعه کنید.

### 21. چگونه می‌توانم مدل‌های جاسازی دیگر را اضافه کنم؟

Dify از موارد زیر برای استفاده به عنوان مدل‌های جاسازی پشتیبانی می‌کند. فقط کافی است نوع `Embeddings` را در کادر تنظیمات انتخاب کنید.

* Azure
* LocalAI
* MiniMax
* OpenAI
* Replicate
* XInference

### 22. چگونه می‌توانم یک برنامه‌ای که ایجاد کرده‌ام را به عنوان یک الگوی برنامه تنظیم کنم؟

این ویژگی الگوهای برنامه را برای کاربران نسخه ابری فراهم می‌کند تا به آن‌ها مراجعه کنند و در حال حاضر از تنظیم برنامه‌های ایجاد شده شما به عنوان الگو پشتیبانی نمی‌کند. اگر از نسخه ابری استفاده می‌کنید، می‌توانید **به Workspace اضافه کنید** یا **سفارشی‌سازی کنید** تا به برنامه خود تبدیل شود. اگر از نسخه جامعه استفاده می‌کنید و نیاز به ایجاد الگوهای برنامه بیشتر برای تیم خود دارید، می‌توانید برای پشتیبانی فنی پرداخت شده با تیم تجاری ما تماس بگیرید: `business@dify.ai`.
