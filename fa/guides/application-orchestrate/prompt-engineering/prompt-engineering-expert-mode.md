# حالت کارشناسی راهنمایی

در حال حاضر، تنظیمات ایجاد برنامه ها در Dify به طور پیش فرض روی **حالت پایه** تنظیم شده است. این حالت برای افرادی که مهارت فنی ندارند و به دنبال ایجاد سریع یک برنامه هستند، ایده آل است. به عنوان مثال، اگر می خواهید یک چت بات برای پایگاه دانش شرکتی یا یک مولد خلاصه مقاله ایجاد کنید، می توانید از **حالت پایه** برای طراحی کلمات `پیش  راهنمایی`، اضافه کردن `سوال`، ادغام `محتوا` و مراحل ساده دیگر برای راه اندازی یک برنامه کامل استفاده کنید. برای اطلاعات بیشتر به 👉 [text-generation-application.md](../../user-guide/creating-dify-apps/prompt-engineering/text-generation-application.md "mention") و [conversation-application.md](../../user-guide/creating-dify-apps/prompt-engineering/conversation-application.md "mention").

💡با این حال، اگر شما یک توسعه دهنده هستید که تحقیقات عمیقی در مورد راهنمایی ها انجام داده اید، مطمئناً می خواهید راهنمایی ها را به روشی سفارشی تر طراحی کنید، در این صورت باید **حالت کارشناسی** را انتخاب کنید. در این حالت، شما مجوز سفارشی کردن راهنمایی های جامع را به جای استفاده از راهنمایی های بسته بندی شده از Dify دریافت می کنید. می توانید راهنمایی های از پیش ساخته شده را تغییر دهید، مکان `محتوا` و `سابقه` را تغییر دهید، پارامترهای لازم را تنظیم کنید و موارد دیگر. اگر با Playground OpenAI آشنا هستید، می توانید به سرعت با این حالت آشنا شوید.

***

خوب، قبل از اینکه این حالت جدید را امتحان کنید، باید از برخی عناصر اساسی در آن آگاه باشید:

*   **Complete**

    هنگامی که یک مدل را انتخاب می کنید، اگر "COMPLETE" را در سمت راست نام مدل می بینید، نشان دهنده یک مدل تکمیل متن است، مانند <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/screenshot-20231017-092613.png" alt="" data-size="line">

    این نوع مدل یک رشته متن آزاد را می پذیرد و یک تکمیل متن تولید می کند و تلاش می کند با هر زمینه یا الگوی که شما ارائه می دهید، مطابقت داشته باشد. به عنوان مثال، اگر راهنمایی `همانطور که رنه دکارت گفت، "من فکر می کنم، بنابراین"` را بنویسید، بسیار محتمل است که مدل `"من هستم."` را به عنوان تکمیل برگرداند. \\
*   **Chat**

    هنگامی که یک مدل را انتخاب می کنید، اگر "CHAT" را در سمت راست نام مدل می بینید، نشان دهنده یک مدل تکمیل چت است، مانند <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/screenshot-20231017-092957.png" alt="" data-size="line">

    این نوع مدل یک لیست از پیام ها را به عنوان ورودی دریافت می کند و یک پیام تولید شده توسط مدل را به عنوان خروجی برمی گرداند. این مدل از سه نوع پیام تشکیل شده است: `SYSTEM`، `USER` و `ASSISTANT`.

    *   `SYSTEM`

        پیام های سیستمی به هدایت رفتار دستیار هوش مصنوعی کمک می کنند. به عنوان مثال، می توانید شخصیت دستیار هوش مصنوعی را تغییر دهید یا دستورالعمل های خاصی در مورد نحوه عملکرد آن در طول مکالمه ارائه دهید. پیام های سیستمی اختیاری هستند. بدون پیام های سیستمی، دستیار هوش مصنوعی ممکن است طوری رفتار کند که از پیام های عمومی مانند `"شما یک دستیار مفید هستید."` استفاده می کند.
    *   `USER`

        پیام های کاربری درخواست ها یا نظرات را برای پاسخ دادن دستیار هوش مصنوعی ارائه می دهند.
    *   `ASSISTANT`

        پیام های دستیار پاسخ های قبلی دستیار را ذخیره می کنند، اما همچنین می توانند توسط شما برای ارائه نمونه هایی از رفتار مورد نظر نوشته شوند. \\
*   **Stop\_Sequences**

    Stop\_Sequences به کلمات، عبارات یا کاراکترهای خاصی اشاره دارد که برای ارسال سیگنال به LLM برای توقف تولید متن استفاده می شود. \\
*   **Blocks**

    <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/Context.png" alt="" data-size="line">

    هنگامی که کاربران یک سوال را وارد می کنند، برنامه سوال را به عنوان معیار جستجو برای دانش پردازش می کند. نتایج سازماندهی شده از جستجو سپس متغیر `Context` را جایگزین می کنند و به LLM اجازه می دهند برای پاسخ خود به محتوا ارجاع دهد.

    <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/QUERY.png" alt="" data-size="line">

    محتوای سوال فقط در مدل های تکمیل متن از برنامه های مکالمه ای در دسترس است. محتوای وارد شده توسط کاربر در طول مکالمه این متغیر را جایگزین می کند و یک نوبت جدید از گفتگو را آغاز می کند.

    <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/history (1).png" alt="" data-size="line">

    سابقه مکالمه فقط در مدل تکمیل متن از برنامه های مکالمه ای در دسترس است. هنگام تعامل در مکالمات متعدد در برنامه های گفتگوی، Dify سوابق گفتگوی تاریخی را با توجه به قوانین از پیش ساخته شده جمع آوری و به هم متصل می کند و متغیر 'سابقه مکالمه' را جایگزین می کند. پیشوندهای `Human` و `Assistant` را می توان با کلیک بر روی `...` بعد از "سابقه مکالمه" تغییر داد. \\
*   **قالب راهنمایی**

    در این حالت، قبل از تنظیم رسمی، یک قالب اولیه در کادر راهنمایی ارائه می شود. ما می توانیم این قالب را به طور مستقیم برای نیازهای سفارشی تر برای LLM تغییر دهیم. انواع مختلف برنامه ها در حالت های مختلف دارای تغییرات هستند.

    برای اطلاعات بیشتر به 👉 [prompt-template.md](prompt-template.md "mention")

***

## مقایسه دو حالت

<table><thead><tr><th width="333">بعد مقایسه</th><th width="197">حالت پایه</th><th>حالت کارشناسی</th></tr></thead><tbody><tr><td>نمایش راهنمایی های از پیش ساخته شده</td><td>نامرئی</td><td>قابل مشاهده</td></tr><tr><td>طراحی خودکار</td><td>موجود</td><td>غیرفعال</td></tr><tr><td>درج متغیر</td><td>موجود</td><td>موجود</td></tr><tr><td>اعتبار سنجی بلوک</td><td>غیرفعال</td><td>موجود</td></tr><tr><td>SYSTEM / USER / ASSISTANT</td><td>نامرئی</td><td>قابل مشاهده</td></tr><tr><td>تنظیمات پارامتر محتوا</td><td>موجود</td><td>موجود</td></tr><tr><td>LOG راهنمایی</td><td>موجود</td><td>موجود</td></tr><tr><td>Stop_Sequences</td><td>غیرفعال</td><td>موجود</td></tr></tbody></table>

## راهنمای عملیاتی

### 1. نحوه ورود به حالت کارشناسی

بعد از ایجاد یک برنامه، می توانید به **حالت کارشناسی** در صفحه طراحی راهنمایی بروید.

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/000.png" alt=""><figcaption><p>دسترسی به <strong>حالت کارشناسی</strong></p></figcaption></figure>

{% hint style="warning" %}
بعد از تغییر راهنمایی ها در **حالت کارشناسی** و انتشار برنامه، نمی توانید به **حالت پایه** برگردید.
{% endhint %}

### 2. تغییر پارامترهای محتوا

در هر دو حالت، می توانید پارامترها را برای درج محتوا تغییر دهید، که شامل **TopK** و **آستانه امتیاز** می شود.

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/Context parameters.png" alt=""><figcaption><p>پارامترهای محتوا</p></figcaption></figure>

{% hint style="warning" %}
لطفاً توجه داشته باشید که فقط بعد از آپلود محتوا، راهنمایی های از پیش ساخته شده حاوی <img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/Context.png" alt="" data-size="line"> در صفحه طراحی راهنمایی نمایش داده می شوند.
{% endhint %}

**TopK:** مقدار یک عدد صحیح از 1 تا 10 است.

این مقدار برای فیلتر کردن قطعات متنی با بیشترین شباهت به سوال کاربر استفاده می شود. سیستم همچنین تعداد قطعات را بر اساس اندازه پنجره محتوا مدل انتخاب شده به طور پویا تنظیم می کند. مقدار پیش فرض سیستم 2 است. این مقدار توصیه می شود بین 2 تا 5 تنظیم شود، زیرا انتظار می رود پاسخ هایی را دریافت کنیم که بیشتر با محتوای تعبیه شده مطابقت دارند. \\

**آستانه امتیاز:** مقدار یک عدد اعشاری از 0 تا 1 است و دارای دو رقم اعشار است.

این مقدار برای تنظیم آستانه شباهت برای انتخاب بخش متن استفاده می شود، به این معنی که فقط قطعات متنی را فراخوانی می کند که از امتیاز تنظیم شده تجاوز می کنند. به طور پیش فرض، سیستم این تنظیم را غیرفعال می کند، به این معنی که هیچ فیلتر کردن بر اساس مقدار شباهت قطعات متنی فراخوانی شده وجود ندارد. هنگامی که فعال می شود، مقدار پیش فرض 0.7 است. ما توصیه می کنیم این تنظیم را به طور پیش فرض غیرفعال نگه دارید. اگر نیازهای پاسخ دقیق تری دارید، می توانید یک مقدار بالاتر را تنظیم کنید، اگرچه توصیه نمی شود آن را به طور غیرعادی بالا تنظیم کنید.

### 3. **Stop\_Sequences**

ما انتظار نداریم که LLM محتوای بیش از حد تولید کند. بنابراین، لازم است کلمات، عبارات یا کاراکترهای خاصی را برای ارسال سیگنال به LLM برای توقف تولید متن تنظیم کنیم. تنظیم پیش فرض `Human:` است. به عنوان مثال، اگر _Few-Shot_ زیر را نوشته اید:

```
Human1: رنگ آسمان چیست؟

Assistant1: آسمان آبی است.

Human1: رنگ آتش چیست؟

Assistant1: آتش قرمز است.

Human1: رنگ خاک چیست؟

Assistant1: 
```

سپس، در پارامترهای مدل، باید `Stop_Sequences` را پیدا کنید و `Human1:` را وارد کنید. فراموش نکنید که کلید `Tab` را فشار دهید. به این ترتیب، LLM فقط با یک جمله در پاسخ به جای تولید هر گونه گفتگوی اضافی پاسخ می دهد:

```
خاک زرد است.
```

زیرا LLM قبل از `Human1:` بعدی تولید محتوا را متوقف می کند.

### 4. استفاده از "/" برای درج متغیرها و بلوک ها

می توانید "/" را در ویرایشگر متن وارد کنید تا بلوک هایی را به سرعت برای درج در راهنمایی به وجود آورید.

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/shortcut.png" alt=""><figcaption><p> میانبر "/"</p></figcaption></figure>

{% hint style="warning" %}
به جز `Variables`، دیگر بلوک ها را نمی توان به طور مکرر درج کرد. در برنامه ها و مدل های مختلف، بلوک هایی که می توان درج کرد، بر اساس ساختارهای مختلف قالب راهنمایی متفاوت هستند.
{% endhint %}

### 5. وارد کردن پیش راهنمایی

قالب راهنمایی اولیه سیستم پارامترها و نیازهای لازم برای پاسخ LLM را ارائه می دهد. برای اطلاعات بیشتر به 👉 [prompt-template.md](prompt-template.md "mention").

هسته توسعه اولیه توسط توسعه دهندگان، پیش راهنمایی برای مکالمه است. این امر به طراحی راهنمایی های از پیش ساخته شده نیاز دارد، با موقعیت درج پیشنهادی در زیر:

```
هنگام پاسخ به کاربر:
- اگر نمی دانید، فقط بگویید که نمی دانید.
- اگر در مورد آن مطمئن نیستید، برای روشن شدن سوال کنید.
از ذکر اینکه اطلاعات را از محتوا به دست آورده اید، خودداری کنید.
و با توجه به زبان سوال کاربر پاسخ دهید.

شما یک دستیار خدمات مشتری برای شرکت اپل هستید و می توانید خدمات مشاوره آیفون را به کاربران ارائه دهید.
هنگام پاسخ دادن، باید مشخصات دقیق آیفون را فهرست کنید و باید این اطلاعات را در یک جدول عمودی {{Format}}  خروجی دهید. اگر لیست خیلی طولانی باشد، باید تغییر داده شود.
مجاز هستید برای تولید خروجی معقول تر، زمان زیادی برای فکر کردن اختصاص دهید.
توجه: شما در حال حاضر فقط دانش بخشی از مدل های آیفون را دارید، نه همه آنها.
```

همچنین می توانید قالب راهنمایی اولیه را سفارشی و تغییر دهید. به عنوان مثال، اگر می خواهید پاسخ های LLM به زبان انگلیسی باشد، می توانید راهنمایی های از پیش ساخته شده را به شرح زیر تغییر دهید:

```
هنگام پاسخ به کاربر:
- اگر نمی دانید، فقط بگویید که نمی دانید.
- اگر در مورد آن مطمئن نیستید، برای روشن شدن سوال کنید.
از ذکر اینکه اطلاعات را از محتوا به دست آورده اید، خودداری کنید.
و با توجه به زبان انگلیسی پاسخ دهید.
```

### 6. بررسی LOG راهنمایی

در طول اشکال زدایی، نه تنها می توانید ورودی کاربر و پاسخ های LLM را بررسی کنید، بلکه می توانید با کلیک بر روی نماد در گوشه بالا سمت چپ دکمه ارسال پیام، راهنمایی های کامل را مشاهده کنید. این امر برای توسعه دهندگان مناسب است تا تأیید کنند که آیا محتوای متغیر ورودی، محتوا، سابقه چت و محتوای سوال مطابق با انتظارات است یا خیر.

#### 6.1 دسترسی به LOG راهنمایی

در رابط پیش نمایش اشکال زدایی، بعد از تعامل با هوش مصنوعی در یک مکالمه، به سادگی نشانگر ماوس را روی هر جلسه کاربر قرار دهید و دکمه نماد "LOG" را در گوشه بالا سمت چپ مشاهده خواهید کرد. برای مشاهده LOG راهنمایی روی آن کلیک کنید.

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/Access to the Prompt Log (1).png" alt=""><figcaption><p>دسترسی به LOG راهنمایی</p></figcaption></figure>

در LOG راهنمایی، ما به وضوح می بینیم:

1. راهنمایی های کامل از پیش ساخته شده.
2. قطعات متنی مرتبط که در جلسه فعلی به آنها ارجاع داده شده است.
3. سوابق جلسه تاریخی.

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/log1.png" alt=""><figcaption><p>LOG راهنمایی</p></figcaption></figure>

از لاگ، می توانیم راهنمایی های کاملی که توسط سیستم جمع آوری و به LLM ارسال شده اند را مشاهده کنیم و می توانیم ورودی راهنمایی را بر اساس نتایج اشکال زدایی به طور مداوم بهبود بخشیم.

#### 6.2 ردیابی تاریخچه اشکال زدایی

در رابط اصلی برنامه اولیه، می توانید "Logs & Ann." را در نوار پیمایش سمت چپ پیدا کنید. با کلیک روی آن می توانید تمام لاگ ها را مشاهده کنید. در رابط اصلی "Logs & Ann."، می توانید روی هر ورودی لاگ مکالمه کلیک کنید. در کادر محاوره ای سمت راست که ظاهر می شود، به سادگی نشانگر ماوس را روی مکالمه قرار دهید و سپس برای بررسی LOG راهنمایی روی دکمه "LOG" کلیک کنید.

برای اطلاعات بیشتر به 👉 [logs.md](../logs.md "mention") .

<figure><img src="/en/.gitbook/assets/guides/application_orchestrate/prompt-engineering/33333.png" alt=""><figcaption><p>Logs &#x26; Ann.</p></figcaption></figure>


